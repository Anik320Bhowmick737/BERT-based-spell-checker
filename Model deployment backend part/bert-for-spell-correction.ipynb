{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-25T13:02:53.890033Z","iopub.status.busy":"2024-07-25T13:02:53.889530Z","iopub.status.idle":"2024-07-25T13:03:00.435271Z","shell.execute_reply":"2024-07-25T13:03:00.434100Z","shell.execute_reply.started":"2024-07-25T13:02:53.889999Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"093a9530f2e04ed7968c983c3cd90082","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eed864165daf400ea5aa1f4c76a46dfa","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21e4f9fcf87249d58e7ef854b9a3876f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47b06d43fe6d4242a2e8e8cc3b271517","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd3c08532ed64232b6b9743266ee0876","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /usr/share/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package words to /usr/share/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["!pip install peft\n","! pip install flask-ngrok\n","! pip install pyngrok\n","import random\n","import torch\n","from transformers import (BertForTokenClassification, AutoTokenizer,BertForMaskedLM)\n","import pandas as pd\n","from datasets import Dataset, DatasetDict\n","from sklearn.model_selection import train_test_split\n","from peft import LoraModel, LoraConfig, get_peft_model\n","import torch\n","import nltk\n","import torch.nn.functional as F\n","from nltk.tokenize import word_tokenize\n","from peft import PeftConfig, PeftModel\n","import copy\n","from flask import Flask, send_from_directory,jsonify,request\n","from flask_ngrok import run_with_ngrok\n","from pyngrok import ngrok\n","\n","BERT = BertForTokenClassification.from_pretrained('google-bert/bert-base-cased',num_labels = 2)\n","Tokenizer =  AutoTokenizer.from_pretrained('google-bert/bert-base-cased')\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('words')"]},{"cell_type":"markdown","metadata":{},"source":["## Get the index of the incorrect words using the trained BERT token classifier"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T13:03:07.258241Z","iopub.status.busy":"2024-07-25T13:03:07.257608Z","iopub.status.idle":"2024-07-25T13:03:07.271506Z","shell.execute_reply":"2024-07-25T13:03:07.270536Z","shell.execute_reply.started":"2024-07-25T13:03:07.258208Z"},"trusted":true},"outputs":[],"source":["def get_incorrect_word(model , sentence):\n","    tokenized_text = word_tokenize(sentence)\n","    #print(tokenized_text)\n","    tokenized_inputs = Tokenizer(tokenized_text, truncation=True ,is_split_into_words=True)\n","    \n","    input_ids = torch.tensor(tokenized_inputs['input_ids']).unsqueeze(0)\n","    \n","    prediction = model(input_ids).logits.argmax(2)[0]\n","    \n","    #print(prediction)\n","    \n","    word_ids = tokenized_inputs.word_ids()\n","    \n","    previous_word_idx = None\n","    \n","    true_predictions = []\n","    \n","    for i,word_idx in enumerate(word_ids):\n","        #print(word_idx)\n","        if word_idx != None and word_idx != previous_word_idx:\n","            true_predictions.append(prediction[i].item())\n","        previous_word_idx = word_idx\n","        \n","    true_predictions = torch.tensor(true_predictions)\n","    \n","    indices = torch.nonzero(true_predictions == 1, as_tuple=False).squeeze()\n","    #print(indices)\n","\n","    if indices.numel() == 0:\n","        return tokenized_text, []\n","        \n","    if indices.dim() == 0:  \n","        indices = indices.unsqueeze(0)\n","    \n","    incorrect_words = [tokenized_text[i.item()] for i in indices]\n","    incorrect_word_indices = [i.item() for i in indices]\n","        \n","    return tokenized_text, incorrect_word_indices"]},{"cell_type":"markdown","metadata":{},"source":["## Get the candidate correction words using BERT Masked Language model"]},{"cell_type":"code","execution_count":347,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:20:26.684105Z","iopub.status.busy":"2024-07-25T14:20:26.683701Z","iopub.status.idle":"2024-07-25T14:20:26.696570Z","shell.execute_reply":"2024-07-25T14:20:26.695520Z","shell.execute_reply.started":"2024-07-25T14:20:26.684074Z"},"trusted":true},"outputs":[],"source":["def get_corrections(LM_model, tokenized_text, incorrect_indices):\n","    \n","    i = 0\n","    deleted_indices = []\n","    lst = copy.deepcopy(incorrect_indices)\n","    #print(lst)\n","    while i < len(lst) - 1:\n","        if lst[i] + 1 == lst[i + 1]:\n","            deleted_indices.append(lst[i + 1])\n","            lst.pop(i+1)\n","            i+=1\n","        else:\n","            i += 1\n","    \n","    #print(deleted_indices)\n","    t_error = copy.deepcopy(tokenized_text)\n","    \n","    #t_error = [t_error[i] for i in range(len(t_error)) if i not in deleted_indices]\n","    \n","    #print(t_error)\n","    # replace with [MASK] tag\n","    for i in lst:\n","        t_error[i]=\"[MASK]\"\n","        \n","    #print(t_error)\n","    \n","    inputs = Tokenizer(t_error, return_tensors=\"pt\",is_split_into_words=True)\n","    with torch.no_grad():\n","        logits = LM_model(**inputs).logits\n","\n","    mask_token_index = (inputs.input_ids == Tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n","    \n","    probs = F.softmax(logits,dim=-1)\n","    top_k=10\n","    top_probs = torch.topk(probs[0, mask_token_index], top_k, sorted=True).indices\n","    #print(top_probs)\n","    highest_probs = top_probs[:,0]\n","    #print(highest_probs)\n","    #print(incorrect_indices)\n","    for idx,highest_prob_idx in zip(lst,highest_probs):\n","        t_error[idx] = Tokenizer.decode(highest_prob_idx.item())\n","        \n","    return \" \".join(t_error)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T13:03:11.037208Z","iopub.status.busy":"2024-07-25T13:03:11.036231Z","iopub.status.idle":"2024-07-25T13:03:15.193303Z","shell.execute_reply":"2024-07-25T13:03:15.192237Z","shell.execute_reply.started":"2024-07-25T13:03:11.037173Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at google-bert/bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["Masked_LMBERT = BertForMaskedLM.from_pretrained(\"google-bert/bert-base-cased\")\n","Reloaded_BERTModel = BertForTokenClassification.from_pretrained('/kaggle/input/bert-trained-spellcheck/Bert for spell check')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T13:03:19.014737Z","iopub.status.busy":"2024-07-25T13:03:19.013990Z","iopub.status.idle":"2024-07-25T13:03:19.440313Z","shell.execute_reply":"2024-07-25T13:03:19.439402Z","shell.execute_reply.started":"2024-07-25T13:03:19.014703Z"},"trusted":true},"outputs":[],"source":["\n","inference_model = PeftModel.from_pretrained(copy.deepcopy(Reloaded_BERTModel), \"/kaggle/input/bert-trained-spellcheck/Lora Adapter/LORA\")"]},{"cell_type":"code","execution_count":343,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:20:09.314493Z","iopub.status.busy":"2024-07-25T14:20:09.314051Z","iopub.status.idle":"2024-07-25T14:20:09.375391Z","shell.execute_reply":"2024-07-25T14:20:09.374399Z","shell.execute_reply.started":"2024-07-25T14:20:09.314462Z"},"trusted":true},"outputs":[],"source":["texts, ids = get_incorrect_word(inference_model , \"\"\"the car done hit by truck\"\"\")"]},{"cell_type":"code","execution_count":344,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:20:09.531393Z","iopub.status.busy":"2024-07-25T14:20:09.530919Z","iopub.status.idle":"2024-07-25T14:20:09.538569Z","shell.execute_reply":"2024-07-25T14:20:09.537423Z","shell.execute_reply.started":"2024-07-25T14:20:09.531329Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[2]"]},"execution_count":344,"metadata":{},"output_type":"execute_result"}],"source":["ids"]},{"cell_type":"code","execution_count":345,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:20:11.555155Z","iopub.status.busy":"2024-07-25T14:20:11.554760Z","iopub.status.idle":"2024-07-25T14:20:11.562478Z","shell.execute_reply":"2024-07-25T14:20:11.561288Z","shell.execute_reply.started":"2024-07-25T14:20:11.555125Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['the', 'car', 'done', 'hit', 'by', 'truck']"]},"execution_count":345,"metadata":{},"output_type":"execute_result"}],"source":["texts"]},{"cell_type":"code","execution_count":348,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:20:32.422088Z","iopub.status.busy":"2024-07-25T14:20:32.421674Z","iopub.status.idle":"2024-07-25T14:20:32.490021Z","shell.execute_reply":"2024-07-25T14:20:32.488832Z","shell.execute_reply.started":"2024-07-25T14:20:32.422054Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'the car was hit by truck'"]},"execution_count":348,"metadata":{},"output_type":"execute_result"}],"source":["get_corrections(Masked_LMBERT, texts, ids)"]},{"cell_type":"markdown","metadata":{},"source":["## Flask backend with ngrok to host the webserver"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-25T14:43:46.717408Z","iopub.status.busy":"2024-07-25T14:43:46.716911Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Ngrok Tunnel URL: NgrokTunnel: \"https://58ac-34-105-117-107.ngrok-free.app\" -> \"http://localhost:5000\"\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n","Usage of ngrok requires a verified account and authtoken.\n","\n","Sign up for an account: https://dashboard.ngrok.com/signup\n","Install your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\n","\n","ERR_NGROK_4018\n","\n"," * Running on http://58ac-34-105-117-107.ngrok-free.app\n"," * Traffic stats available on http://127.0.0.1:4040\n"]}],"source":["app = Flask(__name__)\n","run_with_ngrok(app)\n","path = '/kaggle/input/bertspellcheckfrontendv3/BERT Spellchecker web app'\n","\n","@app.route(\"/\")\n","def html():\n","    return send_from_directory(path, 'index.html')\n","\n","@app.route('/pexels-iriser-1590549.jpg')\n","def image():\n","    return send_from_directory(path, 'pexels-iriser-1590549.jpg')\n","\n","@app.route('/style.css')\n","def style():\n","    return send_from_directory(path, 'style.css')\n","\n","@app.route('/script.js')\n","def script():\n","    return send_from_directory(path, 'script.js')\n","\n","data_store = []\n","@app.route('/submit', methods=['POST'])\n","def submit():\n","    data = request.get_json()\n","    text_input = data.get('txtinput', '')\n","\n","    tokenized_text, indices = get_incorrect_word(inference_model , text_input)\n","    if len(indices)>0:\n","        correction = get_corrections(Masked_LMBERT, tokenized_text, indices)\n","        return jsonify({\n","        'tokenizedText': tokenized_text,\n","        'indices': indices,\n","        'correction':correction})\n","\n","\n","    return jsonify({\n","        'tokenizedText': tokenized_text,\n","        'indices': indices\n","    })\n","\n","if __name__ == '__main__':\n","    ngrok.kill()\n","\n","    ngrok.set_auth_token('GIVE YOUR NGROK TOKEN')\n","\n","    public_url = ngrok.connect(addr='5000')\n","    print(f'Ngrok Tunnel URL: {public_url}')\n","\n","    app.run()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5363567,"sourceId":9025263,"sourceType":"datasetVersion"},{"datasetId":5439509,"sourceId":9025597,"sourceType":"datasetVersion"},{"datasetId":5439647,"sourceId":9026073,"sourceType":"datasetVersion"},{"datasetId":5440545,"sourceId":9027063,"sourceType":"datasetVersion"},{"datasetId":5445089,"sourceId":9033604,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
